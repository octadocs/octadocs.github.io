{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Octadocs Breathe some life into your project documentation. With octadocs, your documentation Belongs to you Octadocs is an extension of MkDocs and is open source. Write docs in plain Markdown files, store them in Git, and deploy anywhere Follows DRY Display information about functions, classes, modules - automatically Supports evolution In one document, illustrate information from multiple versions of your codebase. Illustrate decisions and history of your project Is your friend ...not nuisance. Store your knowledge in a knowledge base. Ask questions and get answers","title":"Octadocs"},{"location":"#with-octadocs-your-documentation","text":"","title":"With octadocs, your documentation"},{"location":"decisions/","text":"","title":"Index"},{"location":"decisions/0001-cache/","text":"Context When developing locally with mkdocs serve , we oftentimes (especially at vocabulari.es ) have long delays before the site updates after every file change. That's because reading the files (say, schema.org ontology) and then running inference rules on them is time consuming. On every file change, MkDocs forces us to rebuild the graph from ground up. We could probably reduce those delays if we could only reload parts of the graph that were actually changed. That is possible because every source file is stored in its own named graph. Decision We see that the OctaDocsPlugin object is recreated every time we change a file while running mkdocs serve . <octadocs.plugin.OctaDocsPlugin object at 0x7fcc8337eee0> <octadocs.plugin.OctaDocsPlugin object at 0x7fcc7fa7e670> We are going to use @functools.lru_cache as an easy caching method. When loading every file into the graph, we will also store the last modification time of the file in a dictionary in memory. When reloading, we only will reload those files which have changed since last time we read them. Using SPARQL CLEAR NAMED statement, we will drop the contents of a file and then read it into the memory again. We will also use CLEAR DEFAULT to wipe previous inference results. Consequences Without large scale modifications of the code, we will speed up development experience a little bit. We will also postpone introductions of any persistent databases a little longer.","title":"Caching the RDF graph in development"},{"location":"decisions/0001-cache/#context","text":"When developing locally with mkdocs serve , we oftentimes (especially at vocabulari.es ) have long delays before the site updates after every file change. That's because reading the files (say, schema.org ontology) and then running inference rules on them is time consuming. On every file change, MkDocs forces us to rebuild the graph from ground up. We could probably reduce those delays if we could only reload parts of the graph that were actually changed. That is possible because every source file is stored in its own named graph.","title":"Context"},{"location":"decisions/0001-cache/#decision","text":"We see that the OctaDocsPlugin object is recreated every time we change a file while running mkdocs serve . <octadocs.plugin.OctaDocsPlugin object at 0x7fcc8337eee0> <octadocs.plugin.OctaDocsPlugin object at 0x7fcc7fa7e670> We are going to use @functools.lru_cache as an easy caching method. When loading every file into the graph, we will also store the last modification time of the file in a dictionary in memory. When reloading, we only will reload those files which have changed since last time we read them. Using SPARQL CLEAR NAMED statement, we will drop the contents of a file and then read it into the memory again. We will also use CLEAR DEFAULT to wipe previous inference results.","title":"Decision"},{"location":"decisions/0001-cache/#consequences","text":"Without large scale modifications of the code, we will speed up development experience a little bit. We will also postpone introductions of any persistent databases a little longer.","title":"Consequences"},{"location":"decisions/0002-nav-to-graph/","text":"Context We would like to represent the structure of navigation tree inside the RDFLib graph of the site. Perhaps we could export the tree as a YAML-LD file for the system to read it? Decision Not likely. To capture the tree we have to use on_nav method, which is executed after all the pages and files are already consumed by the site generator. Thus, we will have to call the graph generation routine from inside of on_nav and write directly to the graph. Consequences This feature will greatly simplify creation of index and list pages using SPARQL queries.","title":"Represent the navigation tree in graph"},{"location":"decisions/0002-nav-to-graph/#context","text":"We would like to represent the structure of navigation tree inside the RDFLib graph of the site. Perhaps we could export the tree as a YAML-LD file for the system to read it?","title":"Context"},{"location":"decisions/0002-nav-to-graph/#decision","text":"Not likely. To capture the tree we have to use on_nav method, which is executed after all the pages and files are already consumed by the site generator. Thus, we will have to call the graph generation routine from inside of on_nav and write directly to the graph.","title":"Decision"},{"location":"decisions/0002-nav-to-graph/#consequences","text":"This feature will greatly simplify creation of index and list pages using SPARQL queries.","title":"Consequences"},{"location":"decisions/0003-calculate-context/","text":"Context (pun not intended) The problem I meet most often when writing YAML-LD is that, by default, in the document like this $id : OntologyTerm label : Class of terms defined by ontologies (RDFS, OWL and others). owl:equivalentClass : $type : owl:Restriction owl:onProperty : rdfs:isDefinedBy owl:someValuesFrom : owl:Ontology the terms owl:Ontology and rdfs:isDefinedBy are interpreted as literals. We want to interpret them as IRIs of course. That can be deduced from definitions in OWL ontology: owl : onProperty a rdf : Property ; rdfs : label \"onProperty\" ; rdfs : comment \"The property that determines the property that a property restriction refers to.\" ; rdfs : domain owl : Restriction ; rdfs : isDefinedBy <http://www.w3.org/2002/07/owl#> ; rdfs : range rdf : Property . The rdfs:range leaves no question as to how to interpret this. Decision We need to select the subset of the graph (for example, the subset encompassing our basic reusable ontologies) which is going to be used to calculate the context object. Then, the context object will be generated from these ontologies, based on definitions like rdf:type , rdfs:domain , rdfs:range and others. Consequences That will ensure the users will not see unexpected and weird frustrations when trying to input information in YAML-LD format.","title":"Calculate a part of Context from ontologies available in the graph"},{"location":"decisions/0003-calculate-context/#context-pun-not-intended","text":"The problem I meet most often when writing YAML-LD is that, by default, in the document like this $id : OntologyTerm label : Class of terms defined by ontologies (RDFS, OWL and others). owl:equivalentClass : $type : owl:Restriction owl:onProperty : rdfs:isDefinedBy owl:someValuesFrom : owl:Ontology the terms owl:Ontology and rdfs:isDefinedBy are interpreted as literals. We want to interpret them as IRIs of course. That can be deduced from definitions in OWL ontology: owl : onProperty a rdf : Property ; rdfs : label \"onProperty\" ; rdfs : comment \"The property that determines the property that a property restriction refers to.\" ; rdfs : domain owl : Restriction ; rdfs : isDefinedBy <http://www.w3.org/2002/07/owl#> ; rdfs : range rdf : Property . The rdfs:range leaves no question as to how to interpret this.","title":"Context (pun not intended)"},{"location":"decisions/0003-calculate-context/#decision","text":"We need to select the subset of the graph (for example, the subset encompassing our basic reusable ontologies) which is going to be used to calculate the context object. Then, the context object will be generated from these ontologies, based on definitions like rdf:type , rdfs:domain , rdfs:range and others.","title":"Decision"},{"location":"decisions/0003-calculate-context/#consequences","text":"That will ensure the users will not see unexpected and weird frustrations when trying to input information in YAML-LD format.","title":"Consequences"},{"location":"decisions/0005-blueprints/","text":"Context Theoretically, Octadocs can support quite complicated use cases and automate the generation of documentation in MkDocs for many particular cases, such as these: Generate a list of ADR documents (such as this one) with status and sorting by creation date; Generate a reveal.js presentation from a directory of Markdown files, one file per slide; Perform a structured search and display its results; Or just display a list of pages as cards. Currently, in order to do any of these things, we'd have to: Create one or more HTML templates for the pages in question; Create a custom context.yaml file and assign it to the pages in question; (Oftentimes) execute one or more inference queries when on_files event fires. How to do that? Decision It could also be useful to expose custom Jinja2 macros to Markdown pages content via mkdocs-macros but, say, for ADR that's not a requirement. I believe some sites can even not need mkdocs-macros at all. That means we are not going to use pluglets as pluggable Octadocs components. What is left is to use MkDocs plugins as such. For example: Run pip install mkdocs-decisions ; Add decisions to plugins sections at mkdocs.yml ; If there is a decisions directory in the site, and it has an index.md document, the ADR index template will be assigned to that file, and any other .md file under that directory will be assigned the ADR template. Consequences All of this will enable us to easily install a plugin and make Octadocs useful even if we do not give a heck about RDF or SPARQL and are not yet prepared to learn anything of the kind.","title":"Introduce Blueprints"},{"location":"decisions/0005-blueprints/#context","text":"Theoretically, Octadocs can support quite complicated use cases and automate the generation of documentation in MkDocs for many particular cases, such as these: Generate a list of ADR documents (such as this one) with status and sorting by creation date; Generate a reveal.js presentation from a directory of Markdown files, one file per slide; Perform a structured search and display its results; Or just display a list of pages as cards. Currently, in order to do any of these things, we'd have to: Create one or more HTML templates for the pages in question; Create a custom context.yaml file and assign it to the pages in question; (Oftentimes) execute one or more inference queries when on_files event fires. How to do that?","title":"Context"},{"location":"decisions/0005-blueprints/#decision","text":"It could also be useful to expose custom Jinja2 macros to Markdown pages content via mkdocs-macros but, say, for ADR that's not a requirement. I believe some sites can even not need mkdocs-macros at all. That means we are not going to use pluglets as pluggable Octadocs components. What is left is to use MkDocs plugins as such. For example: Run pip install mkdocs-decisions ; Add decisions to plugins sections at mkdocs.yml ; If there is a decisions directory in the site, and it has an index.md document, the ADR index template will be assigned to that file, and any other .md file under that directory will be assigned the ADR template.","title":"Decision"},{"location":"decisions/0005-blueprints/#consequences","text":"All of this will enable us to easily install a plugin and make Octadocs useful even if we do not give a heck about RDF or SPARQL and are not yet prepared to learn anything of the kind.","title":"Consequences"},{"location":"decisions/0004-choose-database/","text":"Context At this point, I consider the transient in-memory storage of RDF graph (the one RDFLib provides us with) a blocker for further development because: OWL RL reasoning on this graph is extremely slow; It is impossible to use information from the graph for third-party instruments; There is no interactive UI to debug the graph; The graph is rebuilt from scratch every time we build (or serve) the site. I believe we need to choose a method we are going to persist our data with. Candidates TerminusDB Features Shortcomings Relevant Very nice admin UI WOQL is JSON-LD based Python query DSL Lack for SPARQL support Have to run a separate server process Irrelevant Git-like versioning ? Notes The most important problem in the list above is performance. OWL RL performance is extremely slow and makes the editing experience quite bad even on a modest size documentation database, which I experienced on https://vocabulari.es . This does not yet justify completely rejecting SPARQL as a query standard, or abandoning the principle when you do not need to run an extra DB server to use Octadocs. You just run mkdocs serve and everything works, out of the box. Consequences I will: Enable SQlite storage for RDFLib as the default method; Look into methods to optimize the speed; Optimize context generation and store modification times in the graph rather then in a special dictionary in RAM; Perhaps look into supporting Oxigraph and other SPARQL-enabled stores.","title":"Choosing database engine"},{"location":"decisions/0004-choose-database/#context","text":"At this point, I consider the transient in-memory storage of RDF graph (the one RDFLib provides us with) a blocker for further development because: OWL RL reasoning on this graph is extremely slow; It is impossible to use information from the graph for third-party instruments; There is no interactive UI to debug the graph; The graph is rebuilt from scratch every time we build (or serve) the site. I believe we need to choose a method we are going to persist our data with.","title":"Context"},{"location":"decisions/0004-choose-database/#candidates","text":"","title":"Candidates"},{"location":"decisions/0004-choose-database/#terminusdb","text":"Features Shortcomings Relevant Very nice admin UI WOQL is JSON-LD based Python query DSL Lack for SPARQL support Have to run a separate server process Irrelevant Git-like versioning ?","title":"TerminusDB"},{"location":"decisions/0004-choose-database/#notes","text":"The most important problem in the list above is performance. OWL RL performance is extremely slow and makes the editing experience quite bad even on a modest size documentation database, which I experienced on https://vocabulari.es . This does not yet justify completely rejecting SPARQL as a query standard, or abandoning the principle when you do not need to run an extra DB server to use Octadocs. You just run mkdocs serve and everything works, out of the box.","title":"Notes"},{"location":"decisions/0004-choose-database/#consequences","text":"I will: Enable SQlite storage for RDFLib as the default method; Look into methods to optimize the speed; Optimize context generation and store modification times in the graph rather then in a special dictionary in RAM; Perhaps look into supporting Oxigraph and other SPARQL-enabled stores.","title":"Consequences"},{"location":"octarine/owl-restrictions/","text":"What about this? from octarine import owl , rdfs , var with var . term as term : owl . Restriction ( variable = term , on_property = rdfs . isDefinedBy , some_values_from = owl . Ontology , )","title":"OWL Restrictions"},{"location":"octavo/","text":"Octavo is the greatest spell book of all. And this section is a set of random examples of Octadocs spells.","title":"Octavo"},{"location":"octavo/comments-are-evil/","text":"The YAML format (which we prevalently use in the whole Octadocs system) supports comments: # The greatest spell book of all $id : Octavo Comments written like that are considered a bad practice because they are not available to the graph. It is better to use rdfs:label , rdfs:comment or even octa:title properties to define all human-readable content in a way available for subsequent analysis. $id : Octavo comment : The greatest spell book of all","title":"Comments are Evil"},{"location":"octavo/great-a-tuin/","text":"","title":"The Great A'Tuin"},{"location":"octavo/yaml-ld/","text":"The primary information definition format in Octadocs is YAML-LD .","title":"YAML-LD"}]}